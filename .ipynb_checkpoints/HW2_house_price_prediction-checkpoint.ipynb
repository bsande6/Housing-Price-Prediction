{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uA3nmwPwyBMX"
   },
   "source": [
    "# ECE 4420/6420 Knowledge Engineering \n",
    "\n",
    "## HW 2\n",
    "\n",
    "---\n",
    "\n",
    "Due on 10/15/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "stVyicl_yGIl"
   },
   "source": [
    "In this homework, we will build a model based on real house sale data from a [Kaggle competition](https://www.kaggle.com/harlfoxem/housesalesprediction). \n",
    "\n",
    "You are expected to\n",
    "\n",
    "1. Implement the preprocessing code.\n",
    "2. Develop a linear regression model.\n",
    "3. Submit the .IPYNB file to Canvas.\n",
    "    - Missing the output after execution may hurt your grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data Sets\n",
    "\n",
    "The competition data are separated into training and test sets. \n",
    "Each record/row includes the property values of the house and attributes such as # of bedroom, sqft_living, sqft_lot. \n",
    "The price of each house, namely the label, is only included in the training data set (it's a competition after all). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MYPxXoI20b98"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xgH-Yitf22sc"
   },
   "source": [
    "We downloaded the data into the current directory. To load the two CSV (Comma Separated Values) files containing training and test data respectively we use Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8F0Yfc2X2CPi"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('kc_house_data_train.csv').to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nV7ywmUB25_h"
   },
   "source": [
    "The training data set includes 16,209 examples, 20 features, and 1 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "THmf3WyP27PM",
    "outputId": "2fd7c73d-e03d-403f-bbea-328410ce9630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16209, 21)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4fxMHe1k3BzZ"
   },
   "source": [
    "Letâ€™s take a look at the first 5 features as well as the label (price) from the first 5 training samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "6sfz9Gtl3C1b",
    "outputId": "336e9d09-15d6-4a07-f1fb-26308424d35c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3291800140, '20141107T000000', 3, 1.0, 1360],\n",
       "        [6699001200, '20150507T000000', 5, 2.5, 3220],\n",
       "        [8651610580, '20141107T000000', 4, 2.5, 2570],\n",
       "        [7732400490, '20141105T000000', 4, 2.5, 2270],\n",
       "        [426069095, '20141014T000000', 3, 2.5, 2070]], dtype=object),\n",
       " array([230000.0, 355000.0, 715000.0, 732350.0, 542950.0], dtype=object))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5, :5], train_data[:5, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first 5 features of the top 5 testing samples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Select columns from the traing and testing `ndarray`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Split the training data into features (`X`) and label (`y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10 pts\n",
    "## Add your code here\n",
    "X = train_data[:, :20]\n",
    "y = train_data[:, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HwTwT20T3KAt"
   },
   "source": [
    "#### Step 2: Select the columns for model training and testing\n",
    "In the training dataset, the first two columns are `id` and `date`. \n",
    "They do not carry any information for prediction purposes. \n",
    "Hence we select the other features and disgard the first two columns.\n",
    "The resultant features are save in the orginal object `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5 pts\n",
    "## Please add code here\n",
    "X = X[:, 2:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resultant arrays have 18 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16209, 18)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data type of the `ndarray`s\n",
    "X = X.astype(np.float64)\n",
    "y = y.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Normalize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ui1WxgCg3Q1E"
   },
   "source": [
    "The ranges of features are quite different.\n",
    "We do not know *a priori* which features are likely to be relevant. \n",
    "Hence it makes sense to treat them equally.\n",
    "We will normalize the data so that all features are of the same order of magnitude.\n",
    "\n",
    "To adjust them to a common scale we rescale them to **zero mean** and **unit variance**. \n",
    "This is accomplished as follows:\n",
    "\n",
    "$$x \\leftarrow \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "Note: \n",
    "1. In the model-training phase, you only have access to the training set and do not know any information about the testing set. Please calculate the means and standard variances using training set.\n",
    "2. In the prediction phase, the model will be applied into the testing data. Since the model is trained using the normalized data, it is necessary to normalize the testing data using the same means and standard variances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Calculate means and variance for each features.\n",
    "\n",
    "You either (1) calculate the means and standard variance using the definitions\n",
    "$$ \\mu = \\frac{1}{n} \\sum_{i=1}^{n} x_i $$\n",
    "$$ \\sigma = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\mu)^2 }$$\n",
    "\n",
    "or (2) leverage the built-in functions `numpy.mean()` and `numpy.std`. References are available at [numpy.mean](https://numpy.org/doc/stable/reference/generated/numpy.mean.html) and [numpy.std](https://numpy.org/doc/stable/reference/generated/numpy.std.html).\n",
    "\n",
    "Store the means and standard variance in `ndarray`s for the downstreaming steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R4ZFD_zD3STa"
   },
   "outputs": [],
   "source": [
    "## 10 pts\n",
    "## Add your code here\n",
    "X_mean = np.mean(X, axis= 0)\n",
    "X_std = np.std(X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The means and standard variances should be `ndarray` instances with 18 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18,)\n",
      "(18,)\n"
     ]
    }
   ],
   "source": [
    "print(X_mean.shape)\n",
    "print(X_std.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Normalize the training data by following:\n",
    "$$x \\leftarrow \\frac{x - \\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5 pts\n",
    "## Add your code here\n",
    "X_normalized = (X-X_mean)/X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5adavFft3yc9",
    "outputId": "9fcb2f17-81d6-4049-f63b-15579afc98ea"
   },
   "source": [
    "#### Step 4: Now validate whether the normalization is successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.18796398e-16 -1.68769790e-16  1.54303808e-16  6.13708329e-18\n",
      "  1.20988213e-16  2.27948808e-17 -1.07398958e-17 -1.63071070e-16\n",
      " -2.67401486e-16  3.11237795e-17  1.49043451e-17 -1.12746987e-15\n",
      "  7.01380947e-18  6.60891540e-14 -5.63121228e-15 -9.33879964e-14\n",
      " -1.84112499e-17  3.94526783e-18]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(X_normalized.mean(axis = 0))\n",
    "print(X_normalized.std(axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ytjd37es4vtq"
   },
   "source": [
    "## Training\n",
    "\n",
    "To get started we train a least squared regression model using the anaytical solution. \n",
    "The output should be a vector `w` which inclues the values of weights and an intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fBqU5YLF8gxg",
    "outputId": "6d69953c-ae0f-4526-c4fc-90015cdb79a0"
   },
   "outputs": [],
   "source": [
    "## 40 pts\n",
    "## Add your code here\n",
    "new_col = np.ones((X_normalized.shape[0], 1))\n",
    "X_normalized = np.append(X_normalized,new_col,1)\n",
    "w = np.dot(np.linalg.pinv(np.dot(X_normalized.transpose(),(X_normalized))),(np.dot(X_normalized.transpose(),y)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-31231.11776077  33234.13701614  79729.96659892   3852.69202941\n",
      "   2142.787858    41028.39989283  41454.19211058  17966.23054341\n",
      " 116834.93549988  75257.99031972  24600.24758306 -77606.19204855\n",
      "   7819.71459086 -31451.66616964  82501.32747877 -32279.6951337\n",
      "  15046.62178361  -9250.42033765]\n"
     ]
    }
   ],
   "source": [
    "print(w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DoV4Ox2K9nm3"
   },
   "source": [
    "##  Predict\n",
    "\n",
    "The model that we obtain in this way can then be applied to the test set. \n",
    "But first, we need to perform the same pre-processing operations for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('kc_house_data_test.csv').to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Select the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5404, 20)\n"
     ]
    }
   ],
   "source": [
    "## 5 pts\n",
    "## Add your code here\n",
    "print(test_data.shape)\n",
    "X_test = test_data[:, 2:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data type\n",
    "X_test = X_test.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Normalized the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5 pts\n",
    "## Add your code here\n",
    "X_mean = np.mean(X, axis= 0)\n",
    "X_std = np.std(X, axis=0)\n",
    "X_test_normalized = (X-X_mean)/X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Add a column of ones\n",
    "There is an extra column of ones when we train the model.\n",
    "In the prediction phase, a column of ones is also needed for testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5 pts\n",
    "## Add your code here\n",
    "new_col = np.ones((X_test_normalized.shape[0], 1))\n",
    "X_test_normalized = np.append(X_test_normalized,new_col,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (16209,19) and (18,) not aligned: 19 (dim 1) != 18 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-9d7ffc159205>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## 10 pts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m## Add your code here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_normalized\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (16209,19) and (18,) not aligned: 19 (dim 1) != 18 (dim 0)"
     ]
    }
   ],
   "source": [
    "## 10 pts\n",
    "## Add your code here\n",
    "y_pred = np.dot(X_test_normalized,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Save the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"kc_house_data_prediction.csv\", y_pred, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean squared error (MSE) is a good measurement for evaluating the performance of the regression model.\n",
    "$$ MSE = \\frac{1}{m} \\sum_{i=1}^{m} (y_i - y\\_pred_i)^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the true price and compare the truth with you prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv('kc_house_data_truth.csv').to_numpy(np.float64).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now please calculate the MSE for your prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5 pts\n",
    "## Add your code here\n",
    "sum = 0\n",
    "for i in range(len(y_test)):\n",
    "    sum += (y_pred[i] - y_test[i]) ** 2\n",
    "    \n",
    "MSE = 1/len(y_test) * sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:e}\".format(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit learn: a machine learning package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` is a well developed machine learning package including the most-common algorithms.\n",
    "Of course, least squared regression is included.\n",
    "You can simply build a model through `import-fit-predict` steps.\n",
    "The code is attached for your comparison.\n",
    "Finally, you can compare the MSE value of scikit-learn with yours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression() # intialize a linear regression model\n",
    "lr.fit(X, y) # train this model\n",
    "y_predict_sklean = lr.predict(X_test)# make prediction using this model\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit learn` provides MSE metric. You can measure in a line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_sklearn = mean_squared_error(y_test, y_predict_sklean) \n",
    "print(\"{:e}\".format(MSE_sklearn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1_house_price_prediction_sol.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
